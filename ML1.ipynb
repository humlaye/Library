{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpPybOJFdDjsrtAX2wJ1fU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/humlaye/Library/blob/main/ML1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUGeoQW6uz36"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "data_test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "print(data.isnull().sum())\n",
        "\n",
        "isimler = [\"yolcu_kimligi\",\"hayatta_kaldı\",\"psınıfı\",\"isim\",\"cinsiyet\",\"yaş\",\"sibsp\",\"parch\",\"bilet\",\"ucret\",\"kabin\",\"binis\"]\n",
        "isimleri = [\"yolcu_kimligi\",\"psınıfı\",\"isim\",\"cinsiyet\",\"yaş\",\"sibsp\",\"parch\",\"bilet\",\"ucret\",\"kabin\",\"binis\"]\n",
        "data.columns = isimler\n",
        "data_test.columns = isimleri\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "x = data[[\"psınıfı\",\"cinsiyet\",\"yaş\",\"sibsp\",\"parch\"]]\n",
        "y = data.iloc[:,1]\n",
        "test = data_test[[\"psınıfı\",\"cinsiyet\",\"yaş\",\"sibsp\",\"parch\"]]\n",
        "print(x.isnull().sum())\n",
        "\n",
        "x.iloc[:,2].fillna(x.iloc[:,2].median(), inplace=True)\n",
        "test.iloc[:,2].fillna(test.iloc[:,2].median(), inplace=True)\n",
        "print(x.isnull().sum())\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "x.iloc[:,1] = le.fit_transform(x.iloc[:,1])\n",
        "\n",
        "le1 = preprocessing.LabelEncoder()\n",
        "test.iloc[:,1] = le1.fit_transform(test.iloc[:,1])\n",
        "\"\"\"\n",
        "ohe = OneHotEncoder()\n",
        "x = ohe.fit_transform(x)\n",
        "\n",
        "ohe1 = OneHotEncoder()\n",
        "test = ohe1.fit_transform(test)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler(with_mean=(False))\n",
        "x = sc.fit_transform(x)\n",
        "\n",
        "y=y.values\n",
        "test=test.values\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(x, y)\n",
        "\n",
        "svm_predict = svm.predict(test)\n",
        "yolcu_kimlik = data_test[[\"yolcu_kimligi\"]]\n",
        "yolcu_kimlik.columns=[\"PassengerId\"]\n",
        "test1 = pd.DataFrame(svm_predict)\n",
        "test1.columns=[\"Survived\"]\n",
        "test1 = pd.concat([yolcu_kimlik,test1],axis=1)\n",
        "test1.to_csv(\"test1.csv\",index=False)\n",
        "\"\"\"\n",
        "x=x.values\n",
        "y=y.values\n",
        "test=test.values\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(x,y)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cvs = cross_val_score(dtc, X=x,y=y,cv=4)\n",
        "print(cvs.mean())\n",
        "print(cvs.std())\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "p = [{\"criterion\":[\"gini\",\"entropy\",\"log_loss\"],\"splitter\":[\"best\",\"entropy\",\"random\"]}]\n",
        "grid = GridSearchCV(dtc, param_grid=p,n_jobs=(-1),cv=10)\n",
        "grid.fit(X=x,y=y)\n",
        "print(\"-----------------\")\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_score_)\n",
        "\n",
        "dtc_predict = dtc.predict(test)\n",
        "\n",
        "yolcu_kimlik = data_test[[\"yolcu_kimligi\"]]\n",
        "yolcu_kimlik.columns=[\"PassengerId\"]\n",
        "test2 = pd.DataFrame(dtc_predict)\n",
        "test2.columns=[\"Survived\"]\n",
        "test2 = pd.concat([yolcu_kimlik,test2],axis=1)\n",
        "test2.to_csv(\"test2.csv\",index=False)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()\n",
        "sc.fit_transform(x)\n",
        "sc1 = StandardScaler()\n",
        "sc1.fit_transform(test)\n",
        " \n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin = LinearRegression()\n",
        "lin.fit(x, y)\n",
        "lin_predict = lin.predict(test)\n",
        "\n",
        "lin_predict = np.round(lin_predict).astype(int)\n",
        "\n",
        "yolcu_kimlik = data_test[[\"yolcu_kimligi\"]]\n",
        "yolcu_kimlik.columns=[\"PassengerId\"]\n",
        "test3 = pd.DataFrame(lin_predict)\n",
        "test3.columns=[\"Survived\"]\n",
        "test3 = pd.concat([yolcu_kimlik,test3],axis=1)\n",
        "test3.to_csv(\"test3.csv\",index=False)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb = gnb.fit(x,y)\n",
        "gnb_predict = gnb.predict(test)\n",
        "\n",
        "yolcu_kimlik = data_test[[\"yolcu_kimligi\"]]\n",
        "yolcu_kimlik.columns=[\"PassengerId\"]\n",
        "test4 = pd.DataFrame(gnb_predict)\n",
        "test4.columns=[\"Survived\"]\n",
        "test4 = pd.concat([yolcu_kimlik,test4],axis=1)\n",
        "test4.to_csv(\"test4.csv\",index=False)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()\n",
        "sc.fit_transform(x)\n",
        "sc1 = StandardScaler()\n",
        "sc1.fit_transform(test)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(3, kernel_initializer='uniform', activation = 'relu' , input_dim = 5))\n",
        "\n",
        "classifier.add(Dense(3, kernel_initializer='uniform', activation = 'relu'))\n",
        "\n",
        "classifier.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss =  'binary_crossentropy' , metrics = ['accuracy'] )\n",
        "\n",
        "classifier.fit(x, y, epochs=50)\n",
        "\n",
        "y_pred = classifier.predict(test)\n",
        "\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "\n",
        "yolcu_kimlik = data_test[[\"yolcu_kimligi\"]]\n",
        "yolcu_kimlik.columns=[\"PassengerId\"]\n",
        "test5 = pd.DataFrame(y_pred)\n",
        "test5.columns=[\"Survived\"]\n",
        "test5 = pd.concat([yolcu_kimlik,test5],axis=1)\n",
        "test5.to_csv(\"test5.csv\",index=False)\n",
        "\n"
      ]
    }
  ]
}